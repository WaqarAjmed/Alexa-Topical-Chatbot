{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJCMTixS_Gl8"
      },
      "source": [
        "**Data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H45mvb-ONK4",
        "outputId": "07a01c98-21e6-4145-f79c-56d41a38799d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LlRMjpqwpjE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/topical_chat.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "D6cliv2myFuR",
        "outputId": "23f9f26a-58df-46d1-ae67-c8f9067dfeee"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-211849b5-5949-4513-aa69-73e9dd356856\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>message</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Are you a fan of Google or Microsoft?</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Both are excellent technology they are helpfu...</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I'm not  a huge fan of Google, but I use it a...</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Google provides online related services and p...</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Yeah, their services are good. I'm just not a...</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188373</th>\n",
              "      <td>8628</td>\n",
              "      <td>Wow, it does not seem like that long. Since I...</td>\n",
              "      <td>Surprised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188374</th>\n",
              "      <td>8628</td>\n",
              "      <td>I havent seen that episode, I might google it...</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188375</th>\n",
              "      <td>8628</td>\n",
              "      <td>I don't think I have either. That's an insane...</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188376</th>\n",
              "      <td>8628</td>\n",
              "      <td>I did, my little brother used to love Thomas ...</td>\n",
              "      <td>Happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188377</th>\n",
              "      <td>8628</td>\n",
              "      <td>It did. Ringo Starr, George Carlin, and Alec ...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>188378 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-211849b5-5949-4513-aa69-73e9dd356856')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-211849b5-5949-4513-aa69-73e9dd356856 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-211849b5-5949-4513-aa69-73e9dd356856');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ed76ed0f-fe67-4da6-854a-e37ebdd15d9e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed76ed0f-fe67-4da6-854a-e37ebdd15d9e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ed76ed0f-fe67-4da6-854a-e37ebdd15d9e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        conversation_id                                            message  \\\n",
              "0                     1              Are you a fan of Google or Microsoft?   \n",
              "1                     1   Both are excellent technology they are helpfu...   \n",
              "2                     1   I'm not  a huge fan of Google, but I use it a...   \n",
              "3                     1   Google provides online related services and p...   \n",
              "4                     1   Yeah, their services are good. I'm just not a...   \n",
              "...                 ...                                                ...   \n",
              "188373             8628   Wow, it does not seem like that long. Since I...   \n",
              "188374             8628   I havent seen that episode, I might google it...   \n",
              "188375             8628   I don't think I have either. That's an insane...   \n",
              "188376             8628   I did, my little brother used to love Thomas ...   \n",
              "188377             8628   It did. Ringo Starr, George Carlin, and Alec ...   \n",
              "\n",
              "                      sentiment  \n",
              "0        Curious to dive deeper  \n",
              "1        Curious to dive deeper  \n",
              "2        Curious to dive deeper  \n",
              "3        Curious to dive deeper  \n",
              "4        Curious to dive deeper  \n",
              "...                         ...  \n",
              "188373                Surprised  \n",
              "188374   Curious to dive deeper  \n",
              "188375   Curious to dive deeper  \n",
              "188376                    Happy  \n",
              "188377                  Neutral  \n",
              "\n",
              "[188378 rows x 3 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THNKp1Ybg1Eo",
        "outputId": "83219f66-0173-40c3-fea1-b1a68c94910d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversation 1:\n",
            "Question:  Are you a fan of Google or Microsoft?\n",
            "Answer:  Both are excellent technology they are helpful in many ways. For the security purpose both are super.\n",
            "\n",
            "Conversation 2:\n",
            "Question:  I'm not  a huge fan of Google, but I use it a lot because I have to. I think they are a monopoly in some sense. \n",
            "Answer:  Google provides online related services and products, which includes online ads, search engine and cloud computing.\n",
            "\n",
            "Conversation 3:\n",
            "Question:  Yeah, their services are good. I'm just not a fan of intrusive they can be on our personal lives. \n",
            "Answer:  Google is leading the alphabet subsidiary and will continue to be the Umbrella company for Alphabet internet interest.\n",
            "\n",
            "Conversation 4:\n",
            "Question:  Did you know Google had hundreds of live goats to cut the grass in the past? \n",
            "Answer:  It is very interesting. Google provide \"Chrome OS\" which is a light weight OS. Google provided a lot of hardware mainly in 2010 to 2015. \n",
            "\n",
            "Conversation 5:\n",
            "Question:  I like Google Chrome. Do you use it as well for your browser? \n",
            "Answer:  Yes.Google is the biggest search engine and Google service figure out top 100 website, including Youtube and Blogger.\n",
            "\n",
            "Conversation 6:\n",
            "Question:  By the way, do you like Fish? \n",
            "Answer:  Yes. They form a sister group of tourniquets- they make the sea water clean and remove the dust from it. Fish is the biggest part in the eco-system.\n",
            "\n",
            "Conversation 7:\n",
            "Question:  Did you know that a seahorse is the only fish to have a neck? \n",
            "Answer:  Freshwater fish only drink water through the skin via Osmosis, Saltwater fish drink water through the mouth. Dolphins are friendly to human beings.\n",
            "\n",
            "Conversation 8:\n",
            "Question:  Interesting, they also have gills. Did you know that jellyfish are immortal? \n",
            "Answer:  Yes. Fish is the important resources of human world wide for the commercial and subsistence fish hunts the fish in the wild fisheries.\n",
            "\n",
            "Conversation 9:\n",
            "Question:  What about cats, do you like cats? I'm a dog fan myself. \n",
            "Answer:  The cat is referred as domestic cat and wild cat. They make our world very clean from rats! \n",
            "\n",
            "Conversation 10:\n",
            "Question:  Yeah, cats can be cool, but they sure do spend a lot of their time sleeping. \n",
            "Answer:  Cats hear the sounds too faint or too high frequency human ears can hear. \n",
            "\n",
            "Conversation 11:\n",
            "Question:  do you like dance?\n",
            "Answer:  Yes  I do. Did you know Bruce Lee was a cha cha dancer?\n",
            "\n",
            "Conversation 12:\n",
            "Question:  Yes he even won a hardcore cha cha championship in 1958\n",
            "Answer:  Yeah. Did you know Tupac was a ballet dancer?\n",
            "\n",
            "Conversation 13:\n",
            "Question:  Yes and he even was in the production of the nutcracker\n",
            "Answer:  Yeah. Ballet dancer go through 4 pairs of shoes a week\n",
            "\n",
            "Conversation 14:\n",
            "Question:  Yes that is a lot of shoes and also a lot of money\n",
            "Answer:  Yeah true. Did you know babies are really good at dancing?\n",
            "\n",
            "Conversation 15:\n",
            "Question:  Yes and they smile more when they hit the beat\n",
            "Answer:  Yeah they are much smarter than we give them credit for\n",
            "\n",
            "Conversation 16:\n",
            "Question:  True Did you know Jackson had a patent on a dancing device?\n",
            "Answer:  Yes it helped him smooth out his dance moves\n",
            "\n",
            "Conversation 17:\n",
            "Question:  Nice. Do you like Shakespeare?\n",
            "Answer:  Yes I do. Do you know that he popularized many phrases\n",
            "\n",
            "Conversation 18:\n",
            "Question:  Yes like good riddance, in my heart of hearts and such\n",
            "Answer:  Yes and then he also invented names like Jessica, Olivia and Miranda\n",
            "\n",
            "Conversation 19:\n",
            "Question:  Yes. And for his works you have to use old english for it to make sense\n",
            "Answer:  Yes otherwise the rhymes and puns do not seem to work out\n",
            "\n",
            "Conversation 20:\n",
            "Question:  Yes. He lived at the same time as Pocahontas too\n",
            "Answer:  I wonder if they met how that would go from there\n",
            "\n",
            "Conversation 21:\n",
            "Question:  Hey what's up do use Google very often?I really love the company and was surprised to hear that it was founded back in 1998.\n",
            "Answer:  i think everyone must use it daily! its become ingrained in every day life\n",
            "\n",
            "Conversation 22:\n",
            "Question:  Agreed. The Google headquarters in Mountain View California is nicknamed the Google Plex.\n",
            "Answer:  thats funny. The current CEO is Sundar Pichai, i didnt know Larry Page was replaced\n",
            "\n",
            "Conversation 23:\n",
            "Question:  Oh yeah I didn't know that either. I also want to go to google Plex to see the goats who mow their lawn by eating it.\n",
            "Answer:  say what now?? they have that??\n",
            "\n",
            "Conversation 24:\n",
            "Question:  Yeah apparently lol! They do that instead of hiring people to mow!\n",
            "Answer:  thats both funny and i guess imaginative. leave it to a huge tech company to employ actual goats!\n",
            "\n",
            "Conversation 25:\n",
            "Question:  Yeah exactly I am sure they are cheaper. One thing I bet they couldn't exploit is fish. I think fish are so cool there is actually a breed of jellyfish that is immortal.\n",
            "Answer:  i had rememered hearing about that before. Immortatlity is wasted on a jellyfish haha. did you know a seahorse is the only fish that has an actual neck?\n",
            "\n",
            "Conversation 26:\n",
            "Question:  That is so funny I guess I never considered a seahorse a fish. The black swallower fish sounds a lot like a snake because it can eat pray that is so large.\n",
            "Answer:  i guess they live up to their name then!\n",
            "\n",
            "Conversation 27:\n",
            "Question:  It seems they do. I also didn't know that there was a difference with how freshwater and saltwater fish drink.\n",
            "Answer:  thats crazy. i wonder why fresh water ones only use osmosis? \n",
            "\n",
            "Conversation 28:\n",
            "Question:  Yeah and saltwater fish are lucky because they can do that and drink through their mouth's.\n",
            "Answer:  seems like fresh water fish got the short end of the stick with that one. Have you ever been to a cat cafe?\n",
            "\n",
            "Conversation 29:\n",
            "Question:  I have never been to a cat cafe no, what about you? Seems like they are popular in Japan and Taiwan.\n",
            "Answer:  no but I would love to! paying hourly to hang out with adorable cats? im in!\n",
            "\n",
            "Conversation 30:\n",
            "Question:  Yeah that would be a lot of fun. I didn't realize that cats sleep so much. Must be nice.\n",
            "Answer:  i guess thats where the phrase \"cat nap\" comes from\n",
            "\n",
            "Conversation 31:\n",
            "Question:  Hi!  do you like to dance?\n",
            "Answer:  I love to dance a lot. How about you?\n",
            "\n",
            "Conversation 32:\n",
            "Question:  I am really bad, but it is a good time.\n",
            "Answer:  Dancing is a lot of fun. Did you know that Bruce Lee was a great dancer?\n",
            "\n",
            "Conversation 33:\n",
            "Question:  I heard that, winning Cha Cha championships and everything!\n",
            "Answer:  Yes that is amazing. He won the Hong Kong cha-cha championship back in 1958 in fact.\n",
            "\n",
            "Conversation 34:\n",
            "Question:  I always just thought of him as a martial arts legend.  Now he is a dance legend of sorts too!\n",
            "Answer:  Yeah!! That is correct. He was a fantastic martial artist. Did you know that Tupac danced ballet in high school?\n",
            "\n",
            "Conversation 35:\n",
            "Question:  Yeah!  He was the mouse king in the Nutcracker.  Thats pretty cool, I would definitely never have guessed that about him.\n",
            "Answer:  Neither did I. That is insane because Tupac was a famous rapper. \n",
            "\n",
            "Conversation 36:\n",
            "Question:  He was indeed, his music is even in the library of congress.\n",
            "Answer:  I didn't know this thanks for sharing.\n",
            "\n",
            "Conversation 37:\n",
            "Question:  Sure thing!  Did you hear about Michael Jackson's special patent shoes?\n",
            "Answer:  No. I know that Michael Jackson was a fantastic dancer but can you tell me more about his patent shoes if you don't mind.\n",
            "\n",
            "Conversation 38:\n",
            "Question:  There was a specific device in his shoes that helped with his extreme lean in some dance moves.\n",
            "Answer:  Wow!!! That is amazing coming from such a talented singer and dancer. I couldn't even dance like that even if I dreamed of it.\n",
            "\n",
            "Conversation 39:\n",
            "Question:  Me neither. I could never be a professional dancer.\n",
            "Answer:  I heard that some professional ballet dancer can go through four pairs of shoes in a week.\n",
            "\n",
            "Conversation 40:\n",
            "Question:  That is crazy!  That can't be cheap for them.\n",
            "Answer:  No. I think its very expensive for them to be professional ballet dancers based on this.\n",
            "\n",
            "Conversation 41:\n",
            "Question:  It has been great chatting but I must go!  Gotta go get my Bruce Lee on, the martial arts part...  definitely not the dance.\n",
            "Answer:  Ha Ha!!! It was so nice chatting with you as well!! Have a nice day!!! Bye\n",
            "\n",
            "Conversation 42:\n",
            "Question:  do you like dance?\n",
            "Answer:  I love it. Did you know Bruce Lee was a dancer?\n",
            "\n",
            "Conversation 43:\n",
            "Question:  Yes he even won a cha cha championship in 1958\n",
            "Answer:  Yeah. Did you know ballet dancers use a lot of shoes?\n",
            "\n",
            "Conversation 44:\n",
            "Question:  Yes they go through 4 pairs in a single week\n",
            "Answer:  Yeah that is a lot of shoes and also a lot of money\n",
            "\n",
            "Conversation 45:\n",
            "Question:  Yeah. Babies are also really good at dancing when they hear music\n",
            "Answer:  Yes and they smile more when they hit the beat\n",
            "\n",
            "Conversation 46:\n",
            "Question:  Yeah pretty cute. Did you know Tupac was a ballet dancer?\n",
            "Answer:  Yes he was in the nutcracker as the mouse king\n",
            "\n",
            "Conversation 47:\n",
            "Question:  Yeah. DO you like SHakespeare?\n",
            "Answer:  I love his work. Did you know he popularized many terms that we use to this day?\n",
            "\n",
            "Conversation 48:\n",
            "Question:  Yes terms like, good riddance, in my heart of heart and such\n",
            "Answer:  Yes. He lives at the same time as Pocahontas did\n",
            "\n",
            "Conversation 49:\n",
            "Question:  I wonder if they had met what he would have written about her.\n",
            "Answer:  Yeah good point. He also invented some women's names\n",
            "\n",
            "Conversation 50:\n",
            "Question:  Yes among those are Olivia, Miranda and Jessica\n",
            "Answer:  Yeah. Did you know that his works have to stick to the old english language to make sense?\n",
            "\n",
            "Conversation 51:\n",
            "Question:  Yes especially with punk and rhymes, they do not work with modern language\n",
            "Answer:  Yeah. Did you know Tchaikozsky donated his skull in hopes it will be used in Shakespeare's plays?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Group messages by conversation ID\n",
        "grouped_data = data.groupby('conversation_id')['message'].apply(list)\n",
        "\n",
        "# Prepare pairs of questions and answers for each conversation\n",
        "conversations = []\n",
        "for _, messages in grouped_data.items():\n",
        "    questions = messages[::2]  # Assuming questions are at even indices\n",
        "    answers = messages[1::2]   # Assuming answers are at odd indices\n",
        "\n",
        "    for question, answer in zip(questions, answers):\n",
        "        conversations.append({'question': question, 'answer': answer})\n",
        "\n",
        "# Print the first few conversations for verification\n",
        "for i, conv in enumerate(conversations):\n",
        "    print(f\"Conversation {i + 1}:\")\n",
        "    print(f\"Question: {conv['question']}\")\n",
        "    print(f\"Answer: {conv['answer']}\\n\")\n",
        "    if i >= 50:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMfvPC7ZhF8f",
        "outputId": "4e6ff1f7-571a-4523-f166-eddeb4777d48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversation 1:\n",
            "Cleaned Question: are you a fan of google or microsoft ?\n",
            "Cleaned Answer: both are excellent technology they are helpful in many ways . for the security purpose both are super .\n",
            "\n",
            "Conversation 2:\n",
            "Cleaned Question: i 'm not a huge fan of google , but i use it a lot because i have to . i think they are a monopoly in some sense .\n",
            "Cleaned Answer: google provides online related services and products , which includes online ads , search engine and cloud computing .\n",
            "\n",
            "Conversation 3:\n",
            "Cleaned Question: yeah , their services are good . i 'm just not a fan of intrusive they can be on our personal lives .\n",
            "Cleaned Answer: google is leading the alphabet subsidiary and will continue to be the umbrella company for alphabet internet interest .\n",
            "\n",
            "Conversation 4:\n",
            "Cleaned Question: did you know google had hundreds of live goats to cut the grass in the past ?\n",
            "Cleaned Answer: it is very interesting . google provide `` chrome os '' which is a light weight os . google provided a lot of hardware mainly in 2010 to 2015 .\n",
            "\n",
            "Conversation 5:\n",
            "Cleaned Question: i like google chrome . do you use it as well for your browser ?\n",
            "Cleaned Answer: yes.google is the biggest search engine and google service figure out top 100 website , including youtube and blogger .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download necessary resources if not already downloaded\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define a function to clean and preprocess the text\n",
        "def clean_and_preprocess(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Join tokens back into a cleaned sentence\n",
        "    cleaned_text = ' '.join(tokens)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "# Clean and preprocess the questions and answers in conversations\n",
        "cleaned_conversations = []\n",
        "for conv in conversations:\n",
        "    cleaned_question = clean_and_preprocess(conv['question'])\n",
        "    cleaned_answer = clean_and_preprocess(conv['answer'])\n",
        "    cleaned_conversations.append({'question': cleaned_question, 'answer': cleaned_answer})\n",
        "\n",
        "# Print the first few cleaned conversations for verification\n",
        "for i, conv in enumerate(cleaned_conversations):\n",
        "    print(f\"Conversation {i + 1}:\")\n",
        "    print(f\"Cleaned Question: {conv['question']}\")\n",
        "    print(f\"Cleaned Answer: {conv['answer']}\\n\")\n",
        "    if i >= 4:  # Print the first 5 cleaned conversations\n",
        "     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRxwwK7c7Z8r",
        "outputId": "3df7b4ec-2435-40ca-fbaf-52b384d67b3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size for questions: 27213\n",
            "Vocabulary size for answers: 28171\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Combine all cleaned questions and answers into separate lists\n",
        "questions = [conv['question'] for conv in cleaned_conversations]\n",
        "answers = [conv['answer'] for conv in cleaned_conversations]\n",
        "\n",
        "# Initialize tokenizers for questions and answers\n",
        "tokenizer_ques = Tokenizer()  # Use <OOV> for out-of-vocabulary words\n",
        "tokenizer_ans = Tokenizer()  # Use <OOV> for out-of-vocabulary words\n",
        "\n",
        "# Fit the tokenizers on the text for questions and answers\n",
        "tokenizer_ques.fit_on_texts(questions)\n",
        "tokenizer_ans.fit_on_texts(answers)\n",
        "\n",
        "# Add '<start>' and '<end>' tokens to the tokenizers' word_index for answers\n",
        "tokenizer_ans.word_index['<start>'] = len(tokenizer_ans.word_index) + 1\n",
        "tokenizer_ans.word_index['<end>'] = len(tokenizer_ans.word_index) + 2\n",
        "\n",
        "# Save the tokenizers to files\n",
        "with open('tokenizer_ques.pkl', 'wb') as tokenizer_ques_file:\n",
        "    pickle.dump(tokenizer_ques, tokenizer_ques_file)\n",
        "with open('tokenizer_ans.pkl', 'wb') as tokenizer_ans_file:\n",
        "    pickle.dump(tokenizer_ans, tokenizer_ans_file)\n",
        "\n",
        "# Convert text to sequences of word indices for questions and answers\n",
        "sequences_ques = tokenizer_ques.texts_to_sequences(questions)\n",
        "sequences_ans = tokenizer_ans.texts_to_sequences(answers)\n",
        "\n",
        "# Find the maximum sequence length for questions and answers separately\n",
        "max_seq_length_ques = max(len(seq) for seq in sequences_ques)\n",
        "max_seq_length_ans = max(len(seq) for seq in sequences_ans)\n",
        "\n",
        "# Pad sequences to make them of the same length for questions and answers\n",
        "padded_sequences_ques = pad_sequences(sequences_ques, maxlen=max_seq_length_ques, padding='post', truncating='post')\n",
        "padded_sequences_ans = pad_sequences(sequences_ans, maxlen=max_seq_length_ans, padding='post', truncating='post')\n",
        "\n",
        "# Create input-output pairs for the encoder-decoder model for questions and answers\n",
        "input_data_ques = padded_sequences_ques[:, :-1]  # Input is the question (remove the last token)\n",
        "output_data_ans = padded_sequences_ans[:, 1:]   # Output is the answer (remove the first token)\n",
        "\n",
        "# Convert input and output sequences to numpy arrays for questions and answers\n",
        "input_data_ques = np.array(input_data_ques)\n",
        "output_data_ans = np.array(output_data_ans)\n",
        "\n",
        "# Print the vocabulary size for questions and answers separately\n",
        "vocab_size_ques = len(tokenizer_ques.word_index)\n",
        "vocab_size_ans = len(tokenizer_ans.word_index)\n",
        "print(f\"Vocabulary size for questions: {vocab_size_ques}\")\n",
        "print(f\"Vocabulary size for answers: {vocab_size_ans}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUgEXsOX1n-W",
        "outputId": "c79ccd0d-4bc8-40b1-afdf-e0e2741308e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "130"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_seq_length_ques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ppqEc11pjZ_",
        "outputId": "f514be32-bc37-4901-abd4-05b67125e8d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_seq_length_ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "715mb5po2I50"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Create a dictionary to store the preprocessed data\n",
        "preprocessed_data = {\n",
        "    'input_data': input_data_ques,\n",
        "    'output_data': output_data_ans,\n",
        "    'tokenizer_ques': tokenizer_ques,  # Use tokenizer_ques\n",
        "    'tokenizer_ans': tokenizer_ans,    # Use tokenizer_ans\n",
        "    'max_seq_length_ques': max_seq_length_ques,  # Update variable names\n",
        "    'max_seq_length_ans': max_seq_length_ans,    # Update variable names\n",
        "    'vocab_size_ques': vocab_size_ques,  # Update variable names\n",
        "    'vocab_size_ans': vocab_size_ans     # Update variable names\n",
        "}\n",
        "\n",
        "# Save the preprocessed data to a file using Pickle\n",
        "with open('preprocessed_data.pkl', 'wb') as file:\n",
        "    pickle.dump(preprocessed_data, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pElg53mOJYh1",
        "outputId": "74d608ab-229c-4149-bf5b-1b0900ece017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes of training data:\n",
            "Encoder input: (72939, 129)\n",
            "Decoder input: (72939, 131)\n",
            "Decoder output: (72939, 131)\n",
            "\n",
            "Shapes of validation data:\n",
            "Encoder input: (18235, 129)\n",
            "Decoder input: (18235, 131)\n",
            "Decoder output: (18235, 131)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "encoder_input_train, encoder_input_val, decoder_input_train, decoder_input_val, decoder_output_train, decoder_output_val = train_test_split(\n",
        "    input_data_ques, output_data_ans, output_data_ans, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Print the shapes of the training and validation sets\n",
        "print(\"Shapes of training data:\")\n",
        "print(f\"Encoder input: {encoder_input_train.shape}\")\n",
        "print(f\"Decoder input: {decoder_input_train.shape}\")\n",
        "print(f\"Decoder output: {decoder_output_train.shape}\")\n",
        "\n",
        "print(\"\\nShapes of validation data:\")\n",
        "print(f\"Encoder input: {encoder_input_val.shape}\")\n",
        "print(f\"Decoder input: {decoder_input_val.shape}\")\n",
        "print(f\"Decoder output: {decoder_output_val.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6qoTSwadnuo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define a function for batch one-hot encoding\n",
        "def batch_one_hot_encode(sequences, vocab_size):\n",
        "    batch_size = 32  # Adjust this batch size as needed\n",
        "    num_batches = len(sequences) // batch_size\n",
        "    encoded_sequences = []\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        batch = sequences[i * batch_size : (i + 1) * batch_size]\n",
        "        encoded_batch = tf.one_hot(batch, depth=vocab_size)\n",
        "        encoded_sequences.append(encoded_batch)\n",
        "\n",
        "    # Handle the remaining sequences (if any)\n",
        "    remaining = len(sequences) % batch_size\n",
        "    if remaining > 0:\n",
        "        batch = sequences[-remaining:]\n",
        "        encoded_batch = tf.one_hot(batch, depth=vocab_size)\n",
        "        encoded_sequences.append(encoded_batch)\n",
        "\n",
        "    return tf.concat(encoded_sequences, axis=0)\n",
        "\n",
        "# Example usage\n",
        "decoder_output_train_encoded = batch_one_hot_encode(output_data_ans, vocab_size_ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cpY3_4qumz1",
        "outputId": "55097f01-b0f0-4b78-9d37-4759d8b5806d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes of your data:\n",
            "Encoder input: (91174,)\n",
            "Decoder input: (91174,)\n",
            "\n",
            "Sample 1\n",
            "Encoder Input: ['are you a fan of google or microsoft']\n",
            "Decoder Input: ['both are excellent technology they are helpful in many ways for the security purpose both are super']\n",
            "\n",
            "Sample 2\n",
            "Encoder Input: [\"i 'm not a huge fan of google but i use it a lot because i have to i think they are a monopoly in some sense\"]\n",
            "Decoder Input: ['google provides online related services and products which includes online ads search engine and cloud computing']\n",
            "\n",
            "Sample 3\n",
            "Encoder Input: [\"yeah their services are good i 'm just not a fan of intrusive they can be on our personal lives\"]\n",
            "Decoder Input: ['google is leading the alphabet subsidiary and will continue to be the umbrella company for alphabet internet interest']\n",
            "\n",
            "Sample 4\n",
            "Encoder Input: ['did you know google had hundreds of live goats to cut the grass in the past']\n",
            "Decoder Input: [\"it is very interesting google provide chrome os '' which is a light weight os google provided a lot of hardware mainly in 2010 to 2015\"]\n",
            "\n",
            "Sample 5\n",
            "Encoder Input: ['i like google chrome do you use it as well for your browser']\n",
            "Decoder Input: ['yes google is the biggest search engine and google service figure out top 100 website including youtube and blogger']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-60d110272ef8>:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  print(\"Encoder input:\", np.array(sequences_ques).shape)\n",
            "<ipython-input-11-60d110272ef8>:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  print(\"Decoder input:\", np.array(sequences_ans).shape)\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Load the tokenizers\n",
        "with open('tokenizer_ques.pkl', 'rb') as tokenizer_ques_file:\n",
        "    tokenizer_ques = pickle.load(tokenizer_ques_file)\n",
        "\n",
        "with open('tokenizer_ans.pkl', 'rb') as tokenizer_ans_file:\n",
        "    tokenizer_ans = pickle.load(tokenizer_ans_file)\n",
        "\n",
        "# Load your sequences or data as needed\n",
        "# For example:\n",
        "# sequences_ques = load_sequences('encoder_sequences.pkl')\n",
        "# sequences_ans = load_sequences('decoder_sequences.pkl')\n",
        "\n",
        "# Verify the shapes of your data\n",
        "print(\"Shapes of your data:\")\n",
        "print(\"Encoder input:\", np.array(sequences_ques).shape)\n",
        "print(\"Decoder input:\", np.array(sequences_ans).shape)\n",
        "\n",
        "# Sample inspection\n",
        "for i in range(5):  # Print the first 5 samples\n",
        "    print(\"\\nSample\", i + 1)\n",
        "    print(\"Encoder Input:\", tokenizer_ques.sequences_to_texts([sequences_ques[i]]))\n",
        "    print(\"Decoder Input:\", tokenizer_ans.sequences_to_texts([sequences_ans[i]]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy6xcKWo2izs"
      },
      "outputs": [],
      "source": [
        "class MyDataset(tf.keras.utils.Sequence):\n",
        "    def __init__(self, encoder_input, decoder_input, decoder_output, tknizer_ques, tknizer_ans, max_len):\n",
        "        self.encoder_input = encoder_input.tolist()\n",
        "        self.decoder_input = decoder_input.tolist()\n",
        "        self.decoder_output = decoder_output.tolist()\n",
        "        self.tknizer_ques = tknizer_ques\n",
        "        self.tknizer_ans = tknizer_ans\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoder_input)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        encoder_input = self.encoder_input[i]\n",
        "        decoder_input = self.decoder_input[i]\n",
        "        decoder_output = self.decoder_output[i]\n",
        "\n",
        "        # Ensure the inputs are strings\n",
        "        encoder_input = str(encoder_input)\n",
        "        decoder_input = str(decoder_input)\n",
        "        decoder_output = str(decoder_output)\n",
        "\n",
        "        encoder_seq = self.tknizer_ques.texts_to_sequences([encoder_input])[0]\n",
        "        decoder_inp_seq = self.tknizer_ans.texts_to_sequences([decoder_input])[0]\n",
        "        decoder_out_seq = self.tknizer_ans.texts_to_sequences([decoder_output])[0]\n",
        "\n",
        "        encoder_seq = pad_sequences([encoder_seq], maxlen=self.max_len, padding='post')[0]\n",
        "        decoder_inp_seq = pad_sequences([decoder_inp_seq], maxlen=self.max_len, padding='post')[0]\n",
        "        decoder_out_seq = pad_sequences([decoder_out_seq], maxlen=self.max_len, padding='post')[0]\n",
        "\n",
        "        return [encoder_seq, decoder_inp_seq], decoder_out_seq\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        indices = np.arange(len(self.encoder_input))\n",
        "        np.random.shuffle(indices)\n",
        "        self.encoder_input = [self.encoder_input[i] for i in indices]\n",
        "        self.decoder_input = [self.decoder_input[i] for i in indices]\n",
        "        self.decoder_output = [self.decoder_output[i] for i in indices]\n",
        "\n",
        "class Dataloder(tf.keras.utils.Sequence):\n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset))\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        encoder_seqs = np.stack([item[0][0] for item in data], axis=0)\n",
        "        decoder_inp_seqs = np.stack([item[0][1] for item in data], axis=0)\n",
        "        decoder_out_seqs = np.stack([item[1] for item in data], axis=0)\n",
        "\n",
        "        return [encoder_seqs, decoder_inp_seqs], decoder_out_seqs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI0p3MrArUXO"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.vocab_size = inp_vocab_size\n",
        "        self.embedding_dim = embedding_size\n",
        "        self.input_length = input_length\n",
        "        self.lstm_size = lstm_size\n",
        "        self.lstm_output = 0\n",
        "        self.lstm_state_h=0\n",
        "        self.lstm_state_c=0\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim,\n",
        "                                   input_length=self.input_length,mask_zero=True, name=\"embedding_layer_encoder\",     )\n",
        "        self.lstm = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "\n",
        "    def call(self,input_sequence, training=True):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        input_embedd = self.embedding(input_sequence)\n",
        "        #states=self.lstm_state_h,self.lstm_state_c\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)\n",
        "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
        "\n",
        "\n",
        "    def initialize_states(self,batch_size):\n",
        "   #   '''\n",
        "   #   Given a batch size it will return intial hidden state and intial cell state.\n",
        "   #   If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "   #   '''\n",
        "        #self.batch_size=batch_size\n",
        "        hidden_state=np.zeros((batch_size,self.lstm_size), dtype=float, order='C')\n",
        "        cell_state=np.zeros((batch_size, self.lstm_size), dtype=float, order='C')\n",
        "\n",
        "        return hidden_state, cell_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIZTXWBFzbk9"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.vocab_size = out_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.input_length = input_length\n",
        "\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size,\n",
        "                                   input_length=self.input_length,mask_zero=True,\n",
        "                                   name=\"embedding_layer_decoder\", trainable=False)\n",
        "        self.lstm = LSTM(self.lstm_size, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "\n",
        "    def call(self,input_sequence,states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
        "\n",
        "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
        "        '''\n",
        "        state_h = states[0]\n",
        "        state_c = states[1]\n",
        "        embedd = self.embedding(input_sequence)\n",
        "        lstm_output,final_state_h,final_state_c = self.lstm(embedd, initial_state=[state_h, state_c])\n",
        "\n",
        "        return lstm_output, final_state_h, final_state_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn8HFYpUzbQT"
      },
      "outputs": [],
      "source": [
        "class Encoder_decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self,encoder_inputs_length,decoder_inputs_length, output_vocab_size):\n",
        "        super().__init__()\n",
        "        #Create encoder object\n",
        "        self.encoder = Encoder(inp_vocab_size=vocab_size_ques+1,embedding_size =100,\n",
        "                               lstm_size =512,input_length=encoder_inputs_length)\n",
        "        #Create decoder object\n",
        "        self.decoder = Decoder(vocab_size_ans+1,embedding_size=100,\n",
        "                               lstm_size =512,input_length = decoder_inputs_length)\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "        self.Dense = Dense(output_vocab_size, activation='softmax')\n",
        "\n",
        "    def call(self, data):\n",
        "\n",
        "        input, output = data[0], data[1]\n",
        "        encoder_output, encoder_h, encoder_c = self.encoder(input)\n",
        "        decode,_,_ = self.decoder(output, [encoder_h, encoder_c])\n",
        "        decoder_ouputs = self.Dense(decode)\n",
        "\n",
        "        return decoder_ouputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-l6qX7imZYJz"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "# Compile the model\n",
        "model = Encoder_decoder(encoder_inputs_length=max_seq_length_ques-1, decoder_inputs_length=max_seq_length_ans-1, output_vocab_size=vocab_size_ans+1)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create training and validation datasets using the custom data generators\n",
        "train_dataset = MyDataset(encoder_input_train, decoder_input_train, decoder_output_train, tokenizer_ques, tokenizer_ans, max_seq_length_ques-1)\n",
        "val_dataset = MyDataset(encoder_input_val, decoder_input_val, decoder_output_val, tokenizer_ques, tokenizer_ans, max_seq_length_ques-1)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=32)\n",
        "val_dataloader = Dataloder(val_dataset, batch_size=32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDMxBw4HIW0l",
        "outputId": "bb27d438-026a-4ec9-e33f-7bace558f241"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of model output: (32, 131, 28172)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "# Create a dummy input tensor with the shape that your model expects\n",
        "dummy_input = [np.zeros((batch_size, max_seq_length_ques-1)), np.zeros((batch_size, max_seq_length_ans-1))]\n",
        "dummy_output = model(dummy_input)\n",
        "\n",
        "# Print the shape of the model's output\n",
        "print(\"Shape of model output:\", dummy_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKZqDuptI7Ya",
        "outputId": "37855747-fe37-4fe0-a2d7-1b6f65e0500b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes of training data:\n",
            "Encoder input: (72939, 129)\n",
            "Decoder input: (72939, 131)\n",
            "Decoder output: (72939, 131)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shapes of training data:\")\n",
        "print(f\"Encoder input: {encoder_input_train.shape}\")\n",
        "print(f\"Decoder input: {decoder_input_train.shape}\")\n",
        "print(f\"Decoder output: {decoder_output_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEznddkUXo3R",
        "outputId": "c0f46918-2e06-4150-af66-72336ad78342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1 samples:\n",
            "Sample 1\n",
            "Encoder Input: 7 16 47 1 32 6 1 86 24 390 30 1 86 68 35 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 6 16 120 38 14 23 93 5 304 1908 256 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 2\n",
            "Encoder Input: 7 105 23 1 51 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 7 2 15 11 21 11 1876 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 3\n",
            "Encoder Input: 21 25 5 1 23 8 52 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 28 21 27 1 29 2 23 7 2 455 7 54 24 8 8 86 51 6 19 40 14 61 2 2 6 28 13 69 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 4\n",
            "Encoder Input: 99 1 15 23 13 71 2 16 9 13 22 53 165 5 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 17 14 23 95 47 18 58 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 5\n",
            "Encoder Input: 12 6 2 168 56 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 1 88 123 47 128 313 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Batch 2 samples:\n",
            "Sample 1\n",
            "Encoder Input: 112 36 12 6 29 9 5 58 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 29 100 91 73 1 48 40 196 2 155 28 12 2 175 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 2\n",
            "Encoder Input: 98 46 120 1 86 2 83 5 19 72 9 2 2018 9 42 73 58 3 16 107 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 1 76 126 7 137 79 42 12 22 180 144 33 23 79 13 69 60 1 4 145 18 10 10 800 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 3\n",
            "Encoder Input: 19 53 4 3 8 107 623 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 12 9 17 66 30 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 4\n",
            "Encoder Input: 3 8 31 22 34 3 8 4 26 11 22 43 66 22 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 4 8 4 10 31 6 15 52 126 59 79 71 78 7 37 16 8 2 32 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 5\n",
            "Encoder Input: 5 2 11 70 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 102 312 3 41 20 9 17 109 380 60 122 5 1 77 122 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Batch 3 samples:\n",
            "Sample 1\n",
            "Encoder Input: 1 97 5 16 8 2 560 9 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 180 37 2 15 144 2 7 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 2\n",
            "Encoder Input: 55 8 4 87 19 4 6 17 3 2 8 2 69 427 32 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 20 22 17 3 9 29 33 28 27 7 3 1 45 4 82 13 9 77 3 14 42 18 134 104 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 3\n",
            "Encoder Input: 1 86 67 64 21 7 37 4 21 61 55 7 15 165 5 2 48 7 42 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 75 52 5 78 2 1 15 10 1 17 1 312 30 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 4\n",
            "Encoder Input: 1 17 107 3 14 250 4 10 48 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 3 18 5 27 4 67 87 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 5\n",
            "Encoder Input: 42 4 3 8 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 1933 8 4 410 11 540 220 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Batch 4 samples:\n",
            "Sample 1\n",
            "Encoder Input: 1 158 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 2\n",
            "Encoder Input: 1 203 13 71 18 107 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 14 71 44 63 33 8 93 4 79 8 21 10 91 73 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 3\n",
            "Encoder Input: 7 105 18 31 8 51 104 4 54 5 30 5 24 43 42 10 2 400 2005 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 110 3 1 48 40 14 23 59 28 14 330 2 26 4 1110 5 65 26 2 201 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 4\n",
            "Encoder Input: 36 105 7 36 7 15 5 25 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 25 1 75 24 74 37 6 28 13 335 18 200 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 5\n",
            "Encoder Input: 3 28 25 1 49 38 66 17 330 33 310 11 5 12 52 32 60 7 28 48 53 25 150 84 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 3 16 37 1 324 6 28 27 114 40 14 87 109 6 20 9 17 1860 8 2 68 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Batch 5 samples:\n",
            "Sample 1\n",
            "Encoder Input: 1 61 55 2 3 8 91 112 1 49 38 15 186 5 25 51 9 4 16 18 7 8 93 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 8 54 73 1 94 11 6 15 10 80 1 70 19 240 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 2\n",
            "Encoder Input: 138 19 67 12 6 18 46 48 1 18 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 12 1 94 215 29 100 4 72 11 8 2 51 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 3\n",
            "Encoder Input: 7 45 8 31 8 30 56 9 44 1 60 36 2 22 84 5 9 62 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 32 9 14 154 2 3 29 67 23 580 10 4 18 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 4\n",
            "Encoder Input: 1 18 2 154 27 1 5 7 93 7 8 4 27 2 168 8 51 30 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 42 27 1 140 77 3 9 42 165 56 26 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Sample 5\n",
            "Encoder Input: 34 2 8 7 8 11 12 24 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "Decoder Output: 2 105 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Loop through the first 5 batches of training data\n",
        "for batch_index in range(5):\n",
        "    encoder_input_batch, decoder_output_batch = train_dataloader[batch_index]\n",
        "\n",
        "    # Decode the tokenized sequences back to text for display\n",
        "    decoded_encoder_input = tokenizer_ques.sequences_to_texts(encoder_input_batch[0])\n",
        "    decoded_decoder_output = tokenizer_ans.sequences_to_texts(decoder_output_batch)\n",
        "\n",
        "    # Print the decoded samples\n",
        "    print(f\"Batch {batch_index + 1} samples:\")\n",
        "    for i in range(min(5, len(decoded_encoder_input))):\n",
        "        print(\"Sample\", i + 1)\n",
        "        print(\"Encoder Input:\", decoded_encoder_input[i])\n",
        "        print(\"Decoder Output:\", decoded_decoder_output[i])\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0rcNYGfTDrR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Check the number of units in the output layer of your model\n",
        "output_units = model.layers[-1].units  # Get the number of units in the last layer\n",
        "\n",
        "# Ensure it matches the vocabulary size\n",
        "if output_units != vocab_size_ans + 1:\n",
        "    # If not, create a new output layer with the correct number of units\n",
        "    new_output_layer = Dense(vocab_size_ans + 1, activation='softmax', name='output_layer')\n",
        "\n",
        "    # Replace the old output layer with the new one\n",
        "    model.layers[-1] = new_output_layer\n",
        "    model.outputs = [new_output_layer.output]\n",
        "\n",
        "# Recompile the model with the correct output layer\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VLvmgnlWqPe",
        "outputId": "57fb02c0-24a8-4c91-aa9f-15415685b37b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes of training data:\n",
            "Encoder input: (72939, 129)\n",
            "Decoder input: (72939, 131)\n",
            "Decoder output: (72939, 131)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shapes of training data:\")\n",
        "print(f\"Encoder input: {encoder_input_train.shape}\")\n",
        "print(f\"Decoder input: {decoder_input_train.shape}\")\n",
        "print(f\"Decoder output: {decoder_output_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "7IPneaSTXM7V",
        "outputId": "cfe0b37d-8143-4044-edd9-bdeb6168e39b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-66024be124fc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, None) and (None, None, 28172) are incompatible\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_dataloader, epochs=10, validation_data=val_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeBHJVc29-I9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}